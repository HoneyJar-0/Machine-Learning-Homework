# HW 5:
## Tasks:
1. Implement stochastic gradient descent for a 3-layer neural network to minimize 1/2 MSE loss
2. Verify that loss and gradient functions are correct by comparing them to correctGrad*.npy (discrepency should be < 1e-5)
   - set the number of hidden layers to 20 for this test
3. Use hyperparameter tuning and architectural exploration to minimize the testing loss. It should be < 82 1/2 MSE
4. Include a screenshot of the training and testing loss values (include last 20 iterations of training) for the best architecture and hyperparameters found
5. show 5 weight vectors used in the network
